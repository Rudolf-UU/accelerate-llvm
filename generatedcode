accelerate-llvm-native> test (suite: nofib-llvm-native, args: +ACC -dverbose -ddump-cc -ACC)

[   0.037] llvm: generated 55 instructions in 9 blocks
[   0.046] llvm: optimisation did work? True
[   0.046] ; ModuleID = 'name_of_a_fused_cluster_7a35320c2f2d8d8e24650398edbc959e2223d17b034c730941c0eb43a4e9b75e'
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-pc-linux-gnu"

; Function Attrs: nofree norecurse nounwind
define i1 @name_of_a_fused_cluster_7a35320c2f2d8d8e24650398edbc959e2223d17b034c730941c0eb43a4e9b75e({ <32 x i32>, { i64*, i64*, i64*, i64 } }* nocapture %arg) local_unnamed_addr #0 {
entry:
  %worksteal.index = getelementptr inbounds { <32 x i32>, { i64*, i64*, i64*, i64 } }, { <32 x i32>, { i64*, i64*, i64*, i64 } }* %arg, i64 0, i32 0, i64 0
  %worksteal.activethreads = getelementptr inbounds { <32 x i32>, { i64*, i64*, i64*, i64 } }, { <32 x i32>, { i64*, i64*, i64*, i64 } }* %arg, i64 0, i32 0, i64 1
  %param.0.ptr = getelementptr inbounds { <32 x i32>, { i64*, i64*, i64*, i64 } }, { <32 x i32>, { i64*, i64*, i64*, i64 } }* %arg, i64 0, i32 1, i32 3
  %param.0 = load i64, i64* %param.0.ptr, align 8
  %out.2.ptr = getelementptr inbounds { <32 x i32>, { i64*, i64*, i64*, i64 } }, { <32 x i32>, { i64*, i64*, i64*, i64 } }* %arg, i64 0, i32 1, i32 2
  %out.2 = load i64*, i64** %out.2.ptr, align 8
  %out.1.ptr = getelementptr inbounds { <32 x i32>, { i64*, i64*, i64*, i64 } }, { <32 x i32>, { i64*, i64*, i64*, i64 } }* %arg, i64 0, i32 1, i32 1
  %out.1 = load i64*, i64** %out.1.ptr, align 8
  %in.0.ptr = getelementptr inbounds { <32 x i32>, { i64*, i64*, i64*, i64 } }, { <32 x i32>, { i64*, i64*, i64*, i64 } }* %arg, i64 0, i32 1, i32 0
  %in.0 = load i64*, i64** %in.0.ptr, align 8
  %0 = add i64 %param.0, 16383
  %1 = sdiv i64 %0, 16384
  %2 = trunc i64 %1 to i32
  %3 = load i32, i32* %worksteal.index, align 4
  %4 = icmp slt i32 %3, %2
  br i1 %4, label %worksteal1.start, label %worksteal1.finished

worksteal1.start:                                 ; preds = %entry
  %5 = atomicrmw add i32* %worksteal.activethreads, i32 1 acquire
  %6 = atomicrmw add i32* %worksteal.index, i32 1 unordered
  %7 = icmp slt i32 %6, %2
  br i1 %7, label %worksteal1.loop.work, label %worksteal1.exit

worksteal1.loop.work:                             ; preds = %worksteal1.start, %while3.exit
  %8 = phi i32 [ %9, %while3.exit ], [ %6, %worksteal1.start ]
  %9 = atomicrmw add i32* %worksteal.index, i32 1 unordered
  %10 = sext i32 %8 to i64
  %11 = shl nsw i64 %10, 14
  %12 = add nsw i64 %11, 16384
  %.not = icmp sgt i64 %12, %param.0
  %13 = select i1 %.not, i64 %param.0, i64 %12
  %14 = icmp sgt i64 %13, %11
  br i1 %14, label %while3.top.preheader, label %while3.exit

while3.top.preheader:                             ; preds = %worksteal1.loop.work
  %15 = sub i64 %13, %11
  %min.iters.check = icmp ult i64 %15, 16
  br i1 %min.iters.check, label %while3.top.preheader26, label %vector.memcheck

vector.memcheck:                                  ; preds = %while3.top.preheader
  %scevgep = getelementptr i64, i64* %out.2, i64 %11
  %scevgep6 = getelementptr i64, i64* %out.2, i64 %13
  %scevgep8 = getelementptr i64, i64* %out.1, i64 %11
  %scevgep10 = getelementptr i64, i64* %out.1, i64 %13
  %scevgep12 = getelementptr i64, i64* %in.0, i64 %11
  %scevgep14 = getelementptr i64, i64* %in.0, i64 %13
  %bound0 = icmp ult i64* %scevgep, %scevgep10
  %bound1 = icmp ult i64* %scevgep8, %scevgep6
  %found.conflict = and i1 %bound0, %bound1
  %bound016 = icmp ult i64* %scevgep, %scevgep14
  %bound117 = icmp ult i64* %scevgep12, %scevgep6
  %found.conflict18 = and i1 %bound016, %bound117
  %conflict.rdx = or i1 %found.conflict, %found.conflict18
  %bound019 = icmp ult i64* %scevgep8, %scevgep14
  %bound120 = icmp ult i64* %scevgep12, %scevgep10
  %found.conflict21 = and i1 %bound019, %bound120
  %conflict.rdx22 = or i1 %conflict.rdx, %found.conflict21
  br i1 %conflict.rdx22, label %while3.top.preheader26, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %15, -16
  %ind.end = add i64 %11, %n.vec
  %16 = add i64 %n.vec, -16
  %17 = lshr exact i64 %16, 4
  %18 = add nuw nsw i64 %17, 1
  %xtraiter = and i64 %18, 1
  %19 = icmp eq i64 %16, 0
  br i1 %19, label %middle.block.unr-lcssa, label %vector.ph.new

vector.ph.new:                                    ; preds = %vector.ph
  %unroll_iter = and i64 %18, 2305843009213693950
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph.new
  %index = phi i64 [ 0, %vector.ph.new ], [ %index.next.1, %vector.body ]
  %niter = phi i64 [ %unroll_iter, %vector.ph.new ], [ %niter.nsub.1, %vector.body ]
  %offset.idx = add i64 %11, %index
  %20 = getelementptr inbounds i64, i64* %in.0, i64 %offset.idx
  %21 = bitcast i64* %20 to <4 x i64>*
  %wide.load = load <4 x i64>, <4 x i64>* %21, align 8, !alias.scope !0
  %22 = getelementptr inbounds i64, i64* %20, i64 4
  %23 = bitcast i64* %22 to <4 x i64>*
  %wide.load23 = load <4 x i64>, <4 x i64>* %23, align 8, !alias.scope !0
  %24 = getelementptr inbounds i64, i64* %20, i64 8
  %25 = bitcast i64* %24 to <4 x i64>*
  %wide.load24 = load <4 x i64>, <4 x i64>* %25, align 8, !alias.scope !0
  %26 = getelementptr inbounds i64, i64* %20, i64 12
  %27 = bitcast i64* %26 to <4 x i64>*
  %wide.load25 = load <4 x i64>, <4 x i64>* %27, align 8, !alias.scope !0
  %28 = add <4 x i64> %wide.load, <i64 2, i64 2, i64 2, i64 2>
  %29 = add <4 x i64> %wide.load23, <i64 2, i64 2, i64 2, i64 2>
  %30 = add <4 x i64> %wide.load24, <i64 2, i64 2, i64 2, i64 2>
  %31 = add <4 x i64> %wide.load25, <i64 2, i64 2, i64 2, i64 2>
  %32 = add <4 x i64> %wide.load, <i64 5, i64 5, i64 5, i64 5>
  %33 = add <4 x i64> %wide.load23, <i64 5, i64 5, i64 5, i64 5>
  %34 = add <4 x i64> %wide.load24, <i64 5, i64 5, i64 5, i64 5>
  %35 = add <4 x i64> %wide.load25, <i64 5, i64 5, i64 5, i64 5>
  %36 = getelementptr inbounds i64, i64* %out.2, i64 %offset.idx
  %37 = bitcast i64* %36 to <4 x i64>*
  store <4 x i64> %28, <4 x i64>* %37, align 8, !alias.scope !3, !noalias !5
  %38 = getelementptr inbounds i64, i64* %36, i64 4
  %39 = bitcast i64* %38 to <4 x i64>*
  store <4 x i64> %29, <4 x i64>* %39, align 8, !alias.scope !3, !noalias !5
  %40 = getelementptr inbounds i64, i64* %36, i64 8
  %41 = bitcast i64* %40 to <4 x i64>*
  store <4 x i64> %30, <4 x i64>* %41, align 8, !alias.scope !3, !noalias !5
  %42 = getelementptr inbounds i64, i64* %36, i64 12
  %43 = bitcast i64* %42 to <4 x i64>*
  store <4 x i64> %31, <4 x i64>* %43, align 8, !alias.scope !3, !noalias !5
  %44 = getelementptr inbounds i64, i64* %out.1, i64 %offset.idx
  %45 = bitcast i64* %44 to <4 x i64>*
  store <4 x i64> %32, <4 x i64>* %45, align 8, !alias.scope !7, !noalias !0
  %46 = getelementptr inbounds i64, i64* %44, i64 4
  %47 = bitcast i64* %46 to <4 x i64>*
  store <4 x i64> %33, <4 x i64>* %47, align 8, !alias.scope !7, !noalias !0
  %48 = getelementptr inbounds i64, i64* %44, i64 8
  %49 = bitcast i64* %48 to <4 x i64>*
  store <4 x i64> %34, <4 x i64>* %49, align 8, !alias.scope !7, !noalias !0
  %50 = getelementptr inbounds i64, i64* %44, i64 12
  %51 = bitcast i64* %50 to <4 x i64>*
  store <4 x i64> %35, <4 x i64>* %51, align 8, !alias.scope !7, !noalias !0
  %index.next = or i64 %index, 16
  %offset.idx.1 = add i64 %11, %index.next
  %52 = getelementptr inbounds i64, i64* %in.0, i64 %offset.idx.1
  %53 = bitcast i64* %52 to <4 x i64>*
  %wide.load.1 = load <4 x i64>, <4 x i64>* %53, align 8, !alias.scope !0
  %54 = getelementptr inbounds i64, i64* %52, i64 4
  %55 = bitcast i64* %54 to <4 x i64>*
  %wide.load23.1 = load <4 x i64>, <4 x i64>* %55, align 8, !alias.scope !0
  %56 = getelementptr inbounds i64, i64* %52, i64 8
  %57 = bitcast i64* %56 to <4 x i64>*
  %wide.load24.1 = load <4 x i64>, <4 x i64>* %57, align 8, !alias.scope !0
  %58 = getelementptr inbounds i64, i64* %52, i64 12
  %59 = bitcast i64* %58 to <4 x i64>*
  %wide.load25.1 = load <4 x i64>, <4 x i64>* %59, align 8, !alias.scope !0
  %60 = add <4 x i64> %wide.load.1, <i64 2, i64 2, i64 2, i64 2>
  %61 = add <4 x i64> %wide.load23.1, <i64 2, i64 2, i64 2, i64 2>
  %62 = add <4 x i64> %wide.load24.1, <i64 2, i64 2, i64 2, i64 2>
  %63 = add <4 x i64> %wide.load25.1, <i64 2, i64 2, i64 2, i64 2>
  %64 = add <4 x i64> %wide.load.1, <i64 5, i64 5, i64 5, i64 5>
  %65 = add <4 x i64> %wide.load23.1, <i64 5, i64 5, i64 5, i64 5>
  %66 = add <4 x i64> %wide.load24.1, <i64 5, i64 5, i64 5, i64 5>
  %67 = add <4 x i64> %wide.load25.1, <i64 5, i64 5, i64 5, i64 5>
  %68 = getelementptr inbounds i64, i64* %out.2, i64 %offset.idx.1
  %69 = bitcast i64* %68 to <4 x i64>*
  store <4 x i64> %60, <4 x i64>* %69, align 8, !alias.scope !3, !noalias !5
  %70 = getelementptr inbounds i64, i64* %68, i64 4
  %71 = bitcast i64* %70 to <4 x i64>*
  store <4 x i64> %61, <4 x i64>* %71, align 8, !alias.scope !3, !noalias !5
  %72 = getelementptr inbounds i64, i64* %68, i64 8
  %73 = bitcast i64* %72 to <4 x i64>*
  store <4 x i64> %62, <4 x i64>* %73, align 8, !alias.scope !3, !noalias !5
  %74 = getelementptr inbounds i64, i64* %68, i64 12
  %75 = bitcast i64* %74 to <4 x i64>*
  store <4 x i64> %63, <4 x i64>* %75, align 8, !alias.scope !3, !noalias !5
  %76 = getelementptr inbounds i64, i64* %out.1, i64 %offset.idx.1
  %77 = bitcast i64* %76 to <4 x i64>*
  store <4 x i64> %64, <4 x i64>* %77, align 8, !alias.scope !7, !noalias !0
  %78 = getelementptr inbounds i64, i64* %76, i64 4
  %79 = bitcast i64* %78 to <4 x i64>*
  store <4 x i64> %65, <4 x i64>* %79, align 8, !alias.scope !7, !noalias !0
  %80 = getelementptr inbounds i64, i64* %76, i64 8
  %81 = bitcast i64* %80 to <4 x i64>*
  store <4 x i64> %66, <4 x i64>* %81, align 8, !alias.scope !7, !noalias !0
  %82 = getelementptr inbounds i64, i64* %76, i64 12
  %83 = bitcast i64* %82 to <4 x i64>*
  store <4 x i64> %67, <4 x i64>* %83, align 8, !alias.scope !7, !noalias !0
  %index.next.1 = add i64 %index, 32
  %niter.nsub.1 = add i64 %niter, -2
  %niter.ncmp.1 = icmp eq i64 %niter.nsub.1, 0
  br i1 %niter.ncmp.1, label %middle.block.unr-lcssa, label %vector.body, !llvm.loop !8

middle.block.unr-lcssa:                           ; preds = %vector.body, %vector.ph
  %index.unr = phi i64 [ 0, %vector.ph ], [ %index.next.1, %vector.body ]
  %lcmp.mod.not = icmp eq i64 %xtraiter, 0
  br i1 %lcmp.mod.not, label %middle.block, label %vector.body.epil

vector.body.epil:                                 ; preds = %middle.block.unr-lcssa
  %offset.idx.epil = add i64 %11, %index.unr
  %84 = getelementptr inbounds i64, i64* %in.0, i64 %offset.idx.epil
  %85 = bitcast i64* %84 to <4 x i64>*
  %wide.load.epil = load <4 x i64>, <4 x i64>* %85, align 8, !alias.scope !0
  %86 = getelementptr inbounds i64, i64* %84, i64 4
  %87 = bitcast i64* %86 to <4 x i64>*
  %wide.load23.epil = load <4 x i64>, <4 x i64>* %87, align 8, !alias.scope !0
  %88 = getelementptr inbounds i64, i64* %84, i64 8
  %89 = bitcast i64* %88 to <4 x i64>*
  %wide.load24.epil = load <4 x i64>, <4 x i64>* %89, align 8, !alias.scope !0
  %90 = getelementptr inbounds i64, i64* %84, i64 12
  %91 = bitcast i64* %90 to <4 x i64>*
  %wide.load25.epil = load <4 x i64>, <4 x i64>* %91, align 8, !alias.scope !0
  %92 = add <4 x i64> %wide.load.epil, <i64 2, i64 2, i64 2, i64 2>
  %93 = add <4 x i64> %wide.load23.epil, <i64 2, i64 2, i64 2, i64 2>
  %94 = add <4 x i64> %wide.load24.epil, <i64 2, i64 2, i64 2, i64 2>
  %95 = add <4 x i64> %wide.load25.epil, <i64 2, i64 2, i64 2, i64 2>
  %96 = add <4 x i64> %wide.load.epil, <i64 5, i64 5, i64 5, i64 5>
  %97 = add <4 x i64> %wide.load23.epil, <i64 5, i64 5, i64 5, i64 5>
  %98 = add <4 x i64> %wide.load24.epil, <i64 5, i64 5, i64 5, i64 5>
  %99 = add <4 x i64> %wide.load25.epil, <i64 5, i64 5, i64 5, i64 5>
  %100 = getelementptr inbounds i64, i64* %out.2, i64 %offset.idx.epil
  %101 = bitcast i64* %100 to <4 x i64>*
  store <4 x i64> %92, <4 x i64>* %101, align 8, !alias.scope !3, !noalias !5
  %102 = getelementptr inbounds i64, i64* %100, i64 4
  %103 = bitcast i64* %102 to <4 x i64>*
  store <4 x i64> %93, <4 x i64>* %103, align 8, !alias.scope !3, !noalias !5
  %104 = getelementptr inbounds i64, i64* %100, i64 8
  %105 = bitcast i64* %104 to <4 x i64>*
  store <4 x i64> %94, <4 x i64>* %105, align 8, !alias.scope !3, !noalias !5
  %106 = getelementptr inbounds i64, i64* %100, i64 12
  %107 = bitcast i64* %106 to <4 x i64>*
  store <4 x i64> %95, <4 x i64>* %107, align 8, !alias.scope !3, !noalias !5
  %108 = getelementptr inbounds i64, i64* %out.1, i64 %offset.idx.epil
  %109 = bitcast i64* %108 to <4 x i64>*
  store <4 x i64> %96, <4 x i64>* %109, align 8, !alias.scope !7, !noalias !0
  %110 = getelementptr inbounds i64, i64* %108, i64 4
  %111 = bitcast i64* %110 to <4 x i64>*
  store <4 x i64> %97, <4 x i64>* %111, align 8, !alias.scope !7, !noalias !0
  %112 = getelementptr inbounds i64, i64* %108, i64 8
  %113 = bitcast i64* %112 to <4 x i64>*
  store <4 x i64> %98, <4 x i64>* %113, align 8, !alias.scope !7, !noalias !0
  %114 = getelementptr inbounds i64, i64* %108, i64 12
  %115 = bitcast i64* %114 to <4 x i64>*
  store <4 x i64> %99, <4 x i64>* %115, align 8, !alias.scope !7, !noalias !0
  br label %middle.block

middle.block:                                     ; preds = %middle.block.unr-lcssa, %vector.body.epil
  %cmp.n = icmp eq i64 %15, %n.vec
  br i1 %cmp.n, label %while3.exit, label %while3.top.preheader26

while3.top.preheader26:                           ; preds = %vector.memcheck, %while3.top.preheader, %middle.block
  %.ph = phi i64 [ %11, %vector.memcheck ], [ %11, %while3.top.preheader ], [ %ind.end, %middle.block ]
  %116 = sub i64 %13, %.ph
  %117 = xor i64 %.ph, -1
  %118 = add i64 %13, %117
  %xtraiter27 = and i64 %116, 3
  %lcmp.mod28.not = icmp eq i64 %xtraiter27, 0
  br i1 %lcmp.mod28.not, label %while3.top.prol.loopexit, label %while3.top.prol

while3.top.prol:                                  ; preds = %while3.top.preheader26, %while3.top.prol
  %119 = phi i64 [ %126, %while3.top.prol ], [ %.ph, %while3.top.preheader26 ]
  %prol.iter = phi i64 [ %prol.iter.sub, %while3.top.prol ], [ %xtraiter27, %while3.top.preheader26 ]
  %120 = getelementptr inbounds i64, i64* %in.0, i64 %119
  %121 = load i64, i64* %120, align 8
  %122 = add i64 %121, 2
  %123 = add i64 %121, 5
  %124 = getelementptr inbounds i64, i64* %out.2, i64 %119
  store i64 %122, i64* %124, align 8
  %125 = getelementptr inbounds i64, i64* %out.1, i64 %119
  store i64 %123, i64* %125, align 8
  %126 = add nsw i64 %119, 1
  %prol.iter.sub = add i64 %prol.iter, -1
  %prol.iter.cmp.not = icmp eq i64 %prol.iter.sub, 0
  br i1 %prol.iter.cmp.not, label %while3.top.prol.loopexit, label %while3.top.prol, !llvm.loop !10

while3.top.prol.loopexit:                         ; preds = %while3.top.prol, %while3.top.preheader26
  %.unr = phi i64 [ %.ph, %while3.top.preheader26 ], [ %126, %while3.top.prol ]
  %127 = icmp ult i64 %118, 3
  br i1 %127, label %while3.exit, label %while3.top

while3.top:                                       ; preds = %while3.top.prol.loopexit, %while3.top
  %128 = phi i64 [ %156, %while3.top ], [ %.unr, %while3.top.prol.loopexit ]
  %129 = getelementptr inbounds i64, i64* %in.0, i64 %128
  %130 = load i64, i64* %129, align 8
  %131 = add i64 %130, 2
  %132 = add i64 %130, 5
  %133 = getelementptr inbounds i64, i64* %out.2, i64 %128
  store i64 %131, i64* %133, align 8
  %134 = getelementptr inbounds i64, i64* %out.1, i64 %128
  store i64 %132, i64* %134, align 8
  %135 = add nsw i64 %128, 1
  %136 = getelementptr inbounds i64, i64* %in.0, i64 %135
  %137 = load i64, i64* %136, align 8
  %138 = add i64 %137, 2
  %139 = add i64 %137, 5
  %140 = getelementptr inbounds i64, i64* %out.2, i64 %135
  store i64 %138, i64* %140, align 8
  %141 = getelementptr inbounds i64, i64* %out.1, i64 %135
  store i64 %139, i64* %141, align 8
  %142 = add nsw i64 %128, 2
  %143 = getelementptr inbounds i64, i64* %in.0, i64 %142
  %144 = load i64, i64* %143, align 8
  %145 = add i64 %144, 2
  %146 = add i64 %144, 5
  %147 = getelementptr inbounds i64, i64* %out.2, i64 %142
  store i64 %145, i64* %147, align 8
  %148 = getelementptr inbounds i64, i64* %out.1, i64 %142
  store i64 %146, i64* %148, align 8
  %149 = add nsw i64 %128, 3
  %150 = getelementptr inbounds i64, i64* %in.0, i64 %149
  %151 = load i64, i64* %150, align 8
  %152 = add i64 %151, 2
  %153 = add i64 %151, 5
  %154 = getelement