accelerate-llvm-native> test (suite: nofib-llvm-native, args: +ACC -dverbose -ddump-cc -ACC)

[   0.072] llvm: generated 50 instructions in 9 blocks
[   0.102] llvm: optimisation did work? True
[   0.104] ; ModuleID = 'name_of_a_fused_cluster_d87a32471f1e6b465607b63ff29d8c553038e6d7d5f545d367e836ae0d97308b'
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-pc-linux-gnu"

; Function Attrs: nofree norecurse nounwind
define i1 @name_of_a_fused_cluster_d87a32471f1e6b465607b63ff29d8c553038e6d7d5f545d367e836ae0d97308b({ <32 x i32>, { i64*, i64*, i64 } }* nocapture %arg) local_unnamed_addr #0 {
entry:
  %worksteal.index = getelementptr inbounds { <32 x i32>, { i64*, i64*, i64 } }, { <32 x i32>, { i64*, i64*, i64 } }* %arg, i64 0, i32 0, i64 0
  %worksteal.activethreads = getelementptr inbounds { <32 x i32>, { i64*, i64*, i64 } }, { <32 x i32>, { i64*, i64*, i64 } }* %arg, i64 0, i32 0, i64 1
  %param.0.ptr = getelementptr inbounds { <32 x i32>, { i64*, i64*, i64 } }, { <32 x i32>, { i64*, i64*, i64 } }* %arg, i64 0, i32 1, i32 2
  %param.0 = load i64, i64* %param.0.ptr, align 8
  %out.1.ptr = getelementptr inbounds { <32 x i32>, { i64*, i64*, i64 } }, { <32 x i32>, { i64*, i64*, i64 } }* %arg, i64 0, i32 1, i32 1
  %out.1 = load i64*, i64** %out.1.ptr, align 8
  %in.0.ptr = getelementptr inbounds { <32 x i32>, { i64*, i64*, i64 } }, { <32 x i32>, { i64*, i64*, i64 } }* %arg, i64 0, i32 1, i32 0
  %in.0 = load i64*, i64** %in.0.ptr, align 8
  %0 = add i64 %param.0, 16383
  %1 = sdiv i64 %0, 16384
  %2 = trunc i64 %1 to i32
  %3 = load i32, i32* %worksteal.index, align 4
  %4 = icmp slt i32 %3, %2
  br i1 %4, label %worksteal1.start, label %worksteal1.finished

worksteal1.start:                                 ; preds = %entry
  %5 = atomicrmw add i32* %worksteal.activethreads, i32 1 acquire
  %6 = atomicrmw add i32* %worksteal.index, i32 1 unordered
  %7 = icmp slt i32 %6, %2
  br i1 %7, label %worksteal1.loop.work, label %worksteal1.exit

worksteal1.loop.work:                             ; preds = %worksteal1.start, %while3.exit
  %8 = phi i32 [ %9, %while3.exit ], [ %6, %worksteal1.start ]
  %9 = atomicrmw add i32* %worksteal.index, i32 1 unordered
  %10 = sext i32 %8 to i64
  %11 = shl nsw i64 %10, 14
  %12 = add nsw i64 %11, 16384
  %.not = icmp sgt i64 %12, %param.0
  %13 = select i1 %.not, i64 %param.0, i64 %12
  %14 = icmp sgt i64 %13, %11
  br i1 %14, label %while3.top.preheader, label %while3.exit

while3.top.preheader:                             ; preds = %worksteal1.loop.work
  %15 = sub i64 %13, %11
  %min.iters.check = icmp ult i64 %15, 16
  br i1 %min.iters.check, label %while3.top.preheader15, label %vector.memcheck

vector.memcheck:                                  ; preds = %while3.top.preheader
  %scevgep = getelementptr i64, i64* %out.1, i64 %11
  %scevgep6 = getelementptr i64, i64* %out.1, i64 %13
  %scevgep8 = getelementptr i64, i64* %in.0, i64 %11
  %scevgep10 = getelementptr i64, i64* %in.0, i64 %13
  %bound0 = icmp ult i64* %scevgep, %scevgep10
  %bound1 = icmp ult i64* %scevgep8, %scevgep6
  %found.conflict = and i1 %bound0, %bound1
  br i1 %found.conflict, label %while3.top.preheader15, label %vector.ph

vector.ph:                                        ; preds = %vector.memcheck
  %n.vec = and i64 %15, -16
  %ind.end = add i64 %11, %n.vec
  %16 = add i64 %n.vec, -16
  %17 = lshr exact i64 %16, 4
  %18 = add nuw nsw i64 %17, 1
  %xtraiter = and i64 %18, 1
  %19 = icmp eq i64 %16, 0
  br i1 %19, label %middle.block.unr-lcssa, label %vector.ph.new

vector.ph.new:                                    ; preds = %vector.ph
  %unroll_iter = and i64 %18, 2305843009213693950
  br label %vector.body

vector.body:                                      ; preds = %vector.body, %vector.ph.new
  %index = phi i64 [ 0, %vector.ph.new ], [ %index.next.1, %vector.body ]
  %niter = phi i64 [ %unroll_iter, %vector.ph.new ], [ %niter.nsub.1, %vector.body ]
  %offset.idx = add i64 %11, %index
  %20 = getelementptr inbounds i64, i64* %in.0, i64 %offset.idx
  %21 = bitcast i64* %20 to <4 x i64>*
  %wide.load = load <4 x i64>, <4 x i64>* %21, align 8, !alias.scope !0
  %22 = getelementptr inbounds i64, i64* %20, i64 4
  %23 = bitcast i64* %22 to <4 x i64>*
  %wide.load12 = load <4 x i64>, <4 x i64>* %23, align 8, !alias.scope !0
  %24 = getelementptr inbounds i64, i64* %20, i64 8
  %25 = bitcast i64* %24 to <4 x i64>*
  %wide.load13 = load <4 x i64>, <4 x i64>* %25, align 8, !alias.scope !0
  %26 = getelementptr inbounds i64, i64* %20, i64 12
  %27 = bitcast i64* %26 to <4 x i64>*
  %wide.load14 = load <4 x i64>, <4 x i64>* %27, align 8, !alias.scope !0
  %28 = add <4 x i64> %wide.load, <i64 2, i64 2, i64 2, i64 2>
  %29 = add <4 x i64> %wide.load12, <i64 2, i64 2, i64 2, i64 2>
  %30 = add <4 x i64> %wide.load13, <i64 2, i64 2, i64 2, i64 2>
  %31 = add <4 x i64> %wide.load14, <i64 2, i64 2, i64 2, i64 2>
  %32 = getelementptr inbounds i64, i64* %out.1, i64 %offset.idx
  %33 = bitcast i64* %32 to <4 x i64>*
  store <4 x i64> %28, <4 x i64>* %33, align 8, !alias.scope !3, !noalias !0
  %34 = getelementptr inbounds i64, i64* %32, i64 4
  %35 = bitcast i64* %34 to <4 x i64>*
  store <4 x i64> %29, <4 x i64>* %35, align 8, !alias.scope !3, !noalias !0
  %36 = getelementptr inbounds i64, i64* %32, i64 8
  %37 = bitcast i64* %36 to <4 x i64>*
  store <4 x i64> %30, <4 x i64>* %37, align 8, !alias.scope !3, !noalias !0
  %38 = getelementptr inbounds i64, i64* %32, i64 12
  %39 = bitcast i64* %38 to <4 x i64>*
  store <4 x i64> %31, <4 x i64>* %39, align 8, !alias.scope !3, !noalias !0
  %index.next = or i64 %index, 16
  %offset.idx.1 = add i64 %11, %index.next
  %40 = getelementptr inbounds i64, i64* %in.0, i64 %offset.idx.1
  %41 = bitcast i64* %40 to <4 x i64>*
  %wide.load.1 = load <4 x i64>, <4 x i64>* %41, align 8, !alias.scope !0
  %42 = getelementptr inbounds i64, i64* %40, i64 4
  %43 = bitcast i64* %42 to <4 x i64>*
  %wide.load12.1 = load <4 x i64>, <4 x i64>* %43, align 8, !alias.scope !0
  %44 = getelementptr inbounds i64, i64* %40, i64 8
  %45 = bitcast i64* %44 to <4 x i64>*
  %wide.load13.1 = load <4 x i64>, <4 x i64>* %45, align 8, !alias.scope !0
  %46 = getelementptr inbounds i64, i64* %40, i64 12
  %47 = bitcast i64* %46 to <4 x i64>*
  %wide.load14.1 = load <4 x i64>, <4 x i64>* %47, align 8, !alias.scope !0
  %48 = add <4 x i64> %wide.load.1, <i64 2, i64 2, i64 2, i64 2>
  %49 = add <4 x i64> %wide.load12.1, <i64 2, i64 2, i64 2, i64 2>
  %50 = add <4 x i64> %wide.load13.1, <i64 2, i64 2, i64 2, i64 2>
  %51 = add <4 x i64> %wide.load14.1, <i64 2, i64 2, i64 2, i64 2>
  %52 = getelementptr inbounds i64, i64* %out.1, i64 %offset.idx.1
  %53 = bitcast i64* %52 to <4 x i64>*
  store <4 x i64> %48, <4 x i64>* %53, align 8, !alias.scope !3, !noalias !0
  %54 = getelementptr inbounds i64, i64* %52, i64 4
  %55 = bitcast i64* %54 to <4 x i64>*
  store <4 x i64> %49, <4 x i64>* %55, align 8, !alias.scope !3, !noalias !0
  %56 = getelementptr inbounds i64, i64* %52, i64 8
  %57 = bitcast i64* %56 to <4 x i64>*
  store <4 x i64> %50, <4 x i64>* %57, align 8, !alias.scope !3, !noalias !0
  %58 = getelementptr inbounds i64, i64* %52, i64 12
  %59 = bitcast i64* %58 to <4 x i64>*
  store <4 x i64> %51, <4 x i64>* %59, align 8, !alias.scope !3, !noalias !0
  %index.next.1 = add i64 %index, 32
  %niter.nsub.1 = add i64 %niter, -2
  %niter.ncmp.1 = icmp eq i64 %niter.nsub.1, 0
  br i1 %niter.ncmp.1, label %middle.block.unr-lcssa, label %vector.body, !llvm.loop !5

middle.block.unr-lcssa:                           ; preds = %vector.body, %vector.ph
  %index.unr = phi i64 [ 0, %vector.ph ], [ %index.next.1, %vector.body ]
  %lcmp.mod.not = icmp eq i64 %xtraiter, 0
  br i1 %lcmp.mod.not, label %middle.block, label %vector.body.epil

vector.body.epil:                                 ; preds = %middle.block.unr-lcssa
  %offset.idx.epil = add i64 %11, %index.unr
  %60 = getelementptr inbounds i64, i64* %in.0, i64 %offset.idx.epil
  %61 = bitcast i64* %60 to <4 x i64>*
  %wide.load.epil = load <4 x i64>, <4 x i64>* %61, align 8, !alias.scope !0
  %62 = getelementptr inbounds i64, i64* %60, i64 4
  %63 = bitcast i64* %62 to <4 x i64>*
  %wide.load12.epil = load <4 x i64>, <4 x i64>* %63, align 8, !alias.scope !0
  %64 = getelementptr inbounds i64, i64* %60, i64 8
  %65 = bitcast i64* %64 to <4 x i64>*
  %wide.load13.epil = load <4 x i64>, <4 x i64>* %65, align 8, !alias.scope !0
  %66 = getelementptr inbounds i64, i64* %60, i64 12
  %67 = bitcast i64* %66 to <4 x i64>*
  %wide.load14.epil = load <4 x i64>, <4 x i64>* %67, align 8, !alias.scope !0
  %68 = add <4 x i64> %wide.load.epil, <i64 2, i64 2, i64 2, i64 2>
  %69 = add <4 x i64> %wide.load12.epil, <i64 2, i64 2, i64 2, i64 2>
  %70 = add <4 x i64> %wide.load13.epil, <i64 2, i64 2, i64 2, i64 2>
  %71 = add <4 x i64> %wide.load14.epil, <i64 2, i64 2, i64 2, i64 2>
  %72 = getelementptr inbounds i64, i64* %out.1, i64 %offset.idx.epil
  %73 = bitcast i64* %72 to <4 x i64>*
  store <4 x i64> %68, <4 x i64>* %73, align 8, !alias.scope !3, !noalias !0
  %74 = getelementptr inbounds i64, i64* %72, i64 4
  %75 = bitcast i64* %74 to <4 x i64>*
  store <4 x i64> %69, <4 x i64>* %75, align 8, !alias.scope !3, !noalias !0
  %76 = getelementptr inbounds i64, i64* %72, i64 8
  %77 = bitcast i64* %76 to <4 x i64>*
  store <4 x i64> %70, <4 x i64>* %77, align 8, !alias.scope !3, !noalias !0
  %78 = getelementptr inbounds i64, i64* %72, i64 12
  %79 = bitcast i64* %78 to <4 x i64>*
  store <4 x i64> %71, <4 x i64>* %79, align 8, !alias.scope !3, !noalias !0
  br label %middle.block

middle.block:                                     ; preds = %middle.block.unr-lcssa, %vector.body.epil
  %cmp.n = icmp eq i64 %15, %n.vec
  br i1 %cmp.n, label %while3.exit, label %while3.top.preheader15

while3.top.preheader15:                           ; preds = %vector.memcheck, %while3.top.preheader, %middle.block
  %.ph = phi i64 [ %11, %vector.memcheck ], [ %11, %while3.top.preheader ], [ %ind.end, %middle.block ]
  %80 = sub i64 %13, %.ph
  %81 = xor i64 %.ph, -1
  %82 = add i64 %13, %81
  %xtraiter16 = and i64 %80, 7
  %lcmp.mod17.not = icmp eq i64 %xtraiter16, 0
  br i1 %lcmp.mod17.not, label %while3.top.prol.loopexit, label %while3.top.prol

while3.top.prol:                                  ; preds = %while3.top.preheader15, %while3.top.prol
  %83 = phi i64 [ %88, %while3.top.prol ], [ %.ph, %while3.top.preheader15 ]
  %prol.iter = phi i64 [ %prol.iter.sub, %while3.top.prol ], [ %xtraiter16, %while3.top.preheader15 ]
  %84 = getelementptr inbounds i64, i64* %in.0, i64 %83
  %85 = load i64, i64* %84, align 8
  %86 = add i64 %85, 2
  %87 = getelementptr inbounds i64, i64* %out.1, i64 %83
  store i64 %86, i64* %87, align 8
  %88 = add nsw i64 %83, 1
  %prol.iter.sub = add i64 %prol.iter, -1
  %prol.iter.cmp.not = icmp eq i64 %prol.iter.sub, 0
  br i1 %prol.iter.cmp.not, label %while3.top.prol.loopexit, label %while3.top.prol, !llvm.loop !7

while3.top.prol.loopexit:                         ; preds = %while3.top.prol, %while3.top.preheader15
  %.unr = phi i64 [ %.ph, %while3.top.preheader15 ], [ %88, %while3.top.prol ]
  %89 = icmp ult i64 %82, 7
  br i1 %89, label %while3.exit, label %while3.top

while3.top:                                       ; preds = %while3.top.prol.loopexit, %while3.top
  %90 = phi i64 [ %130, %while3.top ], [ %.unr, %while3.top.prol.loopexit ]
  %91 = getelementptr inbounds i64, i64* %in.0, i64 %90
  %92 = load i64, i64* %91, align 8
  %93 = add i64 %92, 2
  %94 = getelementptr inbounds i64, i64* %out.1, i64 %90
  store i64 %93, i64* %94, align 8
  %95 = add nsw i64 %90, 1
  %96 = getelementptr inbounds i64, i64* %in.0, i64 %95
  %97 = load i64, i64* %96, align 8
  %98 = add i64 %97, 2
  %99 = getelementptr inbounds i64, i64* %out.1, i64 %95
  store i64 %98, i64* %99, align 8
  %100 = add nsw i64 %90, 2
  %101 = getelementptr inbounds i64, i64* %in.0, i64 %100
  %102 = load i64, i64* %101, align 8
  %103 = add i64 %102, 2
  %104 = getelementptr inbounds i64, i64* %out.1, i64 %100
  store i64 %103, i64* %104, align 8
  %105 = add nsw i64 %90, 3
  %106 = getelementptr inbounds i64, i64* %in.0, i64 %105
  %107 = load i64, i64* %106, align 8
  %108 = add i64 %107, 2
  %109 = getelementptr inbounds i64, i64* %out.1, i64 %105
  store i64 %108, i64* %109, align 8
  %110 = add nsw i64 %90, 4
  %111 = getelementptr inbounds i64, i64* %in.0, i64 %110
  %112 = load i64, i64* %111, align 8
  %113 = add i64 %112, 2
  %114 = getelementptr inbounds i64, i64* %out.1, i64 %110
  store i64 %113, i64* %114, align 8
  %115 = add nsw i64 %90, 5
  %116 = getelementptr inbounds i64, i64* %in.0, i64 %115
  %117 = load i64, i64* %116, align 8
  %118 = add i64 %117, 2
  %119 = getelementptr inbounds i64, i64* %out.1, i64 %115
  store i64 %118, i64* %119, align 8
  %120 = add nsw i64 %90, 6
  %121 = getelementptr inbounds i64, i64* %in.0, i64 %120
  %122 = load i64, i64* %121, align 8
  %123 = add i64 %122, 2
  %124 = getelementptr inbounds i64, i64* %out.1, i64 %120
  store i64 %123, i64* %124, align 8
  %125 = add nsw i64 %90, 7
  %126 = getelementptr inbounds i64, i64* %in.0, i64 %125
  %127 = load i64, i64* %126, align 8
  %128 = add i64 %127, 2
  %129 = getelementptr inbounds i64, i64* %out.1, i64 %125
  store i64 %128, i64* %129, align 8
  %130 = add nsw i64 %90, 8
  %exitcond.not.7 = icmp eq i64 %130, %13
  br i1 %exitcond.not.7, label %while3.exit, label %while3.top, !llvm.loop !9

while3.exit:                                      ; preds = %while3.top.prol.loopexit, %while3.top, %middle.block, %worksteal1.loop.work
  %131 = icmp slt i32 %9, %2
  br i1 %131, label %worksteal1.loop.work, label %worksteal1.exit

worksteal1.exit:                                  ; preds = %while3.exit, %worksteal1.start
  %132 = atomicrmw add i32* %worksteal.activethreads, i32 -1 release
  %133 = icmp eq i32 %132, 1
  br i1 %133, label %worksteal1.exit.last, label %worksteal1.finished

worksteal1.exit.last:                             ; preds = %worksteal1.exit
  %134 = cmpxchg i32* %worksteal.activethreads, i32 0, i32 1 monotonic monotonic
  %135 = extractvalue { i32, i1 } %134, 1
  ret i1 %135

worksteal1.finished:                              ; preds = %worksteal1.exit, %entry
  ret i1 false
}

attributes #0 = { nofree norecurse nounwind }

!0 = !{!1}
!1 = distinct !{!1, !2}
!2 = distinct !{!2, !"LVerDomain"}
!3 = !{!4}
!4 = distinct !{!4, !2}
!5 = distinct !{!5, !6}
!6 = !{!"llvm.